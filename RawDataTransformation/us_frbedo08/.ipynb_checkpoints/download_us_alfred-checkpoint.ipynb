{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:24:38.685278Z",
     "start_time": "2019-06-10T19:24:38.661853Z"
    }
   },
   "outputs": [],
   "source": [
    "# The program runs on Python 3.6\n",
    "# API key for accessing the ALFRED API: 583d28835966b0340e377c34a107da91\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:47:04.671607Z",
     "start_time": "2019-06-10T19:47:04.626565Z"
    }
   },
   "outputs": [],
   "source": [
    "# var_alfred = ['GDPC1', 'GDPCTPI', 'FEDFUNDS', 'PCND', 'PCESV', 'PCDG', 'PRFI', 'PNFI',\n",
    "#               'PCNDGC96', 'PCESVC96', 'PCDGCC96', 'AWHNONAG', 'CE16OV', 'CNP16OV', 'COMPNFB']\n",
    "# var_alfred = ['BCNSDODNS']\n",
    "var_alfred = ['ASHMA']\n",
    "# var_alfred = ['GDPCTPI', 'PRFI', 'PFNI']\n",
    "vmonthdays = {'0331', '0630', '0930', '1231'} # vintage date is the last day of each quarter\n",
    "omonthdays = {'0101', '0401', '0701', '1001'} # observation date is the first day of each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:47:06.413151Z",
     "start_time": "2019-06-10T19:47:06.069046Z"
    }
   },
   "outputs": [],
   "source": [
    "def vintage_dates(start='19470101', end='20190331'):\n",
    "    '''Return a list of all vintage dates between two dates\n",
    "       Make sure the starting/ending dates are either both strings or both datetime objects'''\n",
    "    dates = pd.date_range(start, end)\n",
    "    return [date for date in dates if date.strftime('%m%d') in vmonthdays]\n",
    "\n",
    "vdates = vintage_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download and reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:47:06.953453Z",
     "start_time": "2019-06-10T19:47:06.947339Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'api_key': '583d28835966b0340e377c34a107da91', 'file_type': 'json',\n",
    "          'observation_start': '1947-01-01', 'realtime_start': '1947-01-01', 'realtime_end': '2019-03-31'}\n",
    "url = 'https://api.stlouisfed.org/fred/series/observations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:47:07.254066Z",
     "start_time": "2019-06-10T19:47:07.246463Z"
    }
   },
   "outputs": [],
   "source": [
    "def float_or_nan(x):\n",
    "    '''Convert a string to either a float number or NaN'''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:48:10.764157Z",
     "start_time": "2019-06-10T19:47:07.500612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291aa6b0e0dc4964a961c2d2d305047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Cannot download PFNI series, check request",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-191eb79b588e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'series_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvarname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Cannot download {varname} series, check request'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# convert data type from JSON -> DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot download PFNI series, check request"
     ]
    }
   ],
   "source": [
    "for varindex, varname in tqdm_notebook(enumerate(var_alfred), total=len(var_alfred)):\n",
    "    \n",
    "    # retreive series from ALFRED\n",
    "    params.update({'series_id': varname})\n",
    "    page = requests.get(url, params=params, timeout=20)\n",
    "    assert page.status_code == 200, f'Cannot download {varname} series, check request'\n",
    "    \n",
    "    # convert data type from JSON -> DataFrame\n",
    "    # convert dates from string obj -> datetime obj\n",
    "    observations = pd.DataFrame(page.json()['observations'])\n",
    "    observations['value'] = observations['value'].map(lambda x: float_or_nan(x))\n",
    "    for column in observations.columns:\n",
    "        if column != 'value':\n",
    "            observations[column] = pd.to_datetime(observations[column])\n",
    "    \n",
    "    # keep only observation dates in 'omonthdays'\n",
    "    # change 'date' from datetime obj -> string obj ('1947:Q1')\n",
    "    observations = observations[observations['date'].map(lambda x: x.strftime('%m%d') in omonthdays)]\n",
    "    observations['date'] = observations['date'].map(lambda x: str(x.year) + ':Q' + str((x.month+2)//3))\n",
    "    observations.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # reshape column to ['date', 'vintage', 'value', 'series']\n",
    "    for groupindex, (_, group) in enumerate(observations.groupby('date')):\n",
    "        temp_values = [float('nan')]*len(vdates)\n",
    "        for _, row in group.iterrows():\n",
    "            for index, date in enumerate(vdates):\n",
    "                if row['realtime_start'] <= date <= row['realtime_end']:\n",
    "                    temp_values[index] = row['value']\n",
    "        temp_df = pd.DataFrame({'date': row['date'], 'vintage': vdates, 'value': temp_values, 'series': varname})\n",
    "        df = temp_df if groupindex == 0 else pd.concat([df, temp_df])\n",
    "    \n",
    "    # reshape column to ['date', 'SERIES1_VINTAGE1', 'SERIES1_VINTAGE2', ...]\n",
    "    df['vintage'] = df['vintage'].map(lambda x: str(x.year) + 'Q' + str((x.month+2)//3))\n",
    "    for index, (vintage, vgroup) in enumerate(df[['date', 'value']].groupby(df['vintage'])):\n",
    "        vgroup.columns = ['date', varname + '_' + vintage]\n",
    "        df2 = vgroup if index == 0 else pd.merge(df2, vgroup, how='outer')\n",
    "\n",
    "    # merge all series\n",
    "    df_raw = df2 if varindex == 0 else pd.merge(df_raw, df2, on='date', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:48:10.771127Z",
     "start_time": "2019-06-10T19:47:08.559Z"
    }
   },
   "outputs": [],
   "source": [
    "# save to disk\n",
    "df_raw.to_csv('alfred_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
