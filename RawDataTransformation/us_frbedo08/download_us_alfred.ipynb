{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T19:54:15.300129Z",
     "start_time": "2019-06-10T19:54:15.281456Z"
    }
   },
   "outputs": [],
   "source": [
    "# The program runs on Python 3.6\n",
    "# API key for accessing the ALFRED API: 583d28835966b0340e377c34a107da91\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:00:30.223119Z",
     "start_time": "2019-06-10T20:00:30.213675Z"
    }
   },
   "outputs": [],
   "source": [
    "# var_alfred = ['GDPC1', 'GDPCTPI', 'FEDFUNDS', 'PCND', 'PCESV', 'PCDG', 'PRFI', 'PNFI',\n",
    "#               'PCNDGC96', 'PCESVC96', 'PCDGCC96', 'AWHNONAG', 'CE16OV', 'CNP16OV', 'COMPNFB']\n",
    "# var_alfred = ['BCNSDODNS']\n",
    "# var_alfred = ['ASHMA']\n",
    "var_alfred = ['GDPCTPI', 'PRFI', ] # 'PFNI'\n",
    "vmonthdays = {'0331', '0630', '0930', '1231'} # vintage date is the last day of each quarter\n",
    "omonthdays = {'0101', '0401', '0701', '1001'} # observation date is the first day of each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:00:31.549053Z",
     "start_time": "2019-06-10T20:00:31.243968Z"
    }
   },
   "outputs": [],
   "source": [
    "def vintage_dates(start='19470101', end='20190331'):\n",
    "    '''Return a list of all vintage dates between two dates\n",
    "       Make sure the starting/ending dates are either both strings or both datetime objects'''\n",
    "    dates = pd.date_range(start, end)\n",
    "    return [date for date in dates if date.strftime('%m%d') in vmonthdays]\n",
    "\n",
    "vdates = vintage_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download and reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:00:32.127651Z",
     "start_time": "2019-06-10T20:00:32.118524Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {'api_key': '583d28835966b0340e377c34a107da91', 'file_type': 'json',\n",
    "          'observation_start': '1947-01-01', 'realtime_start': '1947-01-01', 'realtime_end': '2019-03-31'}\n",
    "url = 'https://api.stlouisfed.org/fred/series/observations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:00:32.637847Z",
     "start_time": "2019-06-10T20:00:32.628204Z"
    }
   },
   "outputs": [],
   "source": [
    "def float_or_nan(x):\n",
    "    '''Convert a string to either a float number or NaN'''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:01:34.932512Z",
     "start_time": "2019-06-10T20:00:32.956577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a140ccf89b4cb580d2ba76c8a7aee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for varindex, varname in tqdm_notebook(enumerate(var_alfred), total=len(var_alfred)):\n",
    "    \n",
    "    # retreive series from ALFRED\n",
    "    params.update({'series_id': varname})\n",
    "    page = requests.get(url, params=params, timeout=20)\n",
    "    assert page.status_code == 200, f'Cannot download {varname} series, check request'\n",
    "    \n",
    "    # convert data type from JSON -> DataFrame\n",
    "    # convert dates from string obj -> datetime obj\n",
    "    observations = pd.DataFrame(page.json()['observations'])\n",
    "    observations['value'] = observations['value'].map(lambda x: float_or_nan(x))\n",
    "    for column in observations.columns:\n",
    "        if column != 'value':\n",
    "            observations[column] = pd.to_datetime(observations[column])\n",
    "    \n",
    "    # keep only observation dates in 'omonthdays'\n",
    "    # change 'date' from datetime obj -> string obj ('1947:Q1')\n",
    "    observations = observations[observations['date'].map(lambda x: x.strftime('%m%d') in omonthdays)]\n",
    "    observations['date'] = observations['date'].map(lambda x: str(x.year) + ':Q' + str((x.month+2)//3))\n",
    "    observations.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # reshape column to ['date', 'vintage', 'value', 'series']\n",
    "    for groupindex, (_, group) in enumerate(observations.groupby('date')):\n",
    "        temp_values = [float('nan')]*len(vdates)\n",
    "        for _, row in group.iterrows():\n",
    "            for index, date in enumerate(vdates):\n",
    "                if row['realtime_start'] <= date <= row['realtime_end']:\n",
    "                    temp_values[index] = row['value']\n",
    "        temp_df = pd.DataFrame({'date': row['date'], 'vintage': vdates, 'value': temp_values, 'series': varname})\n",
    "        df = temp_df if groupindex == 0 else pd.concat([df, temp_df])\n",
    "    \n",
    "    # reshape column to ['date', 'SERIES1_VINTAGE1', 'SERIES1_VINTAGE2', ...]\n",
    "    df['vintage'] = df['vintage'].map(lambda x: str(x.year) + 'Q' + str((x.month+2)//3))\n",
    "    for index, (vintage, vgroup) in enumerate(df[['date', 'value']].groupby(df['vintage'])):\n",
    "        vgroup.columns = ['date', varname + '_' + vintage]\n",
    "        df2 = vgroup if index == 0 else pd.merge(df2, vgroup, how='outer')\n",
    "\n",
    "    # merge all series\n",
    "    df_raw = df2 if varindex == 0 else pd.merge(df_raw, df2, on='date', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T20:01:35.165457Z",
     "start_time": "2019-06-10T20:01:34.937663Z"
    }
   },
   "outputs": [],
   "source": [
    "# save to disk\n",
    "df_raw.to_csv('alfred_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
