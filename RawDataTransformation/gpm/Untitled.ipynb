{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('max_columns', 100, 'max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmonthdays = {'0331', '0630', '0930', '1231'} # vintage date is the last day of each quarter\n",
    "omonthdays = {'0101', '0401', '0701', '1001'} # observation date is the first day of each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_variables = ['UNRATE', 'CPIAUCSL', 'GDPC1', 'FEDFUNDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = pd.to_datetime('1947-01-01')\n",
    "enddate = pd.to_datetime('2019-03-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vintage_dates(monthdays, start=startdate, end=enddate):\n",
    "    '''Return a list of all vintage dates between two dates\n",
    "       Make sure the starting/ending dates are either both strings or both datetime objects'''\n",
    "    dates = pd.date_range(start, end)\n",
    "    return [date for date in dates if date.strftime('%m%d') in monthdays]\n",
    "\n",
    "vdates = vintage_dates(monthdays=vmonthdays)\n",
    "odates = vintage_dates(monthdays=omonthdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_or_nan(x):\n",
    "    '''Convert a string to either a float number or NaN'''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'api_key': '583d28835966b0340e377c34a107da91', 'file_type': 'json',\n",
    "          'observation_start': '1947-01-01', 'realtime_start': startdate.strftime('%Y-%m-%d'), 'realtime_end': enddate.strftime('%Y-%m-%d')}\n",
    "url = 'https://api.stlouisfed.org/fred/series/observations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date_range = pd.DataFrame({'dates': pd.date_range(start=startdate, end=enddate)})\n",
    "\n",
    "for varindex, varname in tqdm_notebook(enumerate(fred_variables), total=len(fred_variables)):\n",
    "    \n",
    "    print(f'Downloading {varname} ...')\n",
    "    # retreive series from FRED\n",
    "    params.update({'series_id': varname})\n",
    "    page = requests.get(url, params=params, timeout=20)\n",
    "    assert page.status_code == 200, f'Cannot download {varname} series, check the request command!'\n",
    "    \n",
    "    print(f'Transforming data to DataFrame objects ...')\n",
    "    # convert data type from JSON -> DataFrame\n",
    "    observations = pd.DataFrame(page.json()['observations'])\n",
    "    # convert values from string -> float\n",
    "    observations['value'] = observations['value'].map(lambda x: float_or_nan(x))\n",
    "    # convert dates from string -> datetime\n",
    "    for column in observations.columns:\n",
    "        if column != 'value':\n",
    "            observations[column] = pd.to_datetime(observations[column])\n",
    "    \n",
    "    print(f'Checking data formats ...')\n",
    "    # check the frequency of the data\n",
    "    obs_in_year = Counter(dict(Counter([str(dts)[:4] for dts in observations['date'].unique()])).values()).most_common()[0]\n",
    "    if obs_in_year[0] == 4:\n",
    "        frequency = 'Q'\n",
    "    elif obs_in_year[0] == 12:\n",
    "        frequency = 'M'\n",
    "    elif obs_in_year[0] == 52:\n",
    "        frequency = 'W'\n",
    "    elif obs_in_year[0] > 250:\n",
    "        frequency = 'D'\n",
    "    else:\n",
    "        input(f'Most time there are {obs_in_year[0]} observations in each year, frequency should be (Q, M, W, D): ', frequency)\n",
    "        assert frequency in {'Q', 'M', 'W', 'D'}, f'Wrong frequency!'\n",
    "    \n",
    "    # check whether the data is revised\n",
    "    realtime = set(observations['realtime_start']).union(set(observations['realtime_end']))\n",
    "    if len(realtime) == 1:\n",
    "        revised = 0\n",
    "    else:\n",
    "        revised = 1\n",
    "        \n",
    "    print(f'Reshaping data ...')\n",
    "    # add observation dates\n",
    "    not_observed_dates = set(odates).difference(set(observations['date']))\n",
    "    for date in not_observed_dates:\n",
    "        observations.loc[observations.shape[0], :] = [startdate, enddate, date, float('nan')]\n",
    "    observations.sort_values(by='date', inplace=True)\n",
    "    observations.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f'Reshaping data continued ...')\n",
    "    # add vintage dates reshape column to ['dates', 'vintages', 'values', 'fred_variables']\n",
    "    # if no observation fill with float('nan')\n",
    "    # 'date' -> 'date'\n",
    "    # 'realtime_start' and 'realtime_end' -> 'vintage'\n",
    "    # 'value' -> 'value'\n",
    "    # 'fred_variables' -> name of the variable\n",
    "    for groupindex, (_, group) in enumerate(observations.groupby('date')):\n",
    "        temp_values = [float('nan')]*len(vdates)\n",
    "        for _, row in group.iterrows():\n",
    "            for index, date in enumerate(vdates):\n",
    "                if row['realtime_start'] <= date <= row['realtime_end']:\n",
    "                    temp_values[index] = row['value']\n",
    "        temp_df = pd.DataFrame({'dates': row['date'], 'vintages': vdates, 'values': temp_values, 'fred_variables': varname})\n",
    "        df = temp_df if groupindex == 0 else pd.concat([df, temp_df])\n",
    "        \n",
    "    # find out the minimal vintage and date that are not NaN\n",
    "    # df_withoutnan = df[df['values'].map(lambda x: type(x) == float and not np.isnan(x))].copy()\n",
    "    # min_vintage_withvalue, min_date_withvalue = df_withoutnan.vintages.min(), df_withoutnan.dates.min()\n",
    "\n",
    "    print(f'Reshaping data continued and continued ...')\n",
    "    if not frequency == 'Q':\n",
    "        print('Variable not in quarterly frequency, need to take the average within each quarter: ')\n",
    "    # reshape data structure to\n",
    "    # columns = ['dates', 'fred_variables' 'VINTAGE1', 'VINTAGE2', ...]\n",
    "    # row = ['date1', 'date2', ...]\n",
    "    for vindex, (vintage, vgroup) in enumerate(df[['dates', 'values']].groupby(df['vintages'])):\n",
    "        if not frequency == 'Q':\n",
    "            print(str(vintage.year)[2:]+'Q'+str(vintage.quarter), end=' ')\n",
    "\n",
    "            if frequency in {'W', 'D'}:\n",
    "                vgroup = pd.merge(vgroup, full_date_range, on='dates', how='outer').sort_values(by='dates', ascending=True)\n",
    "\n",
    "            vgroup.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            quarterly_values = []\n",
    "            quarterly_dates = []\n",
    "            next_month = {1:4, 4:7, 7:10, 10:1}\n",
    "\n",
    "            for index, row in vgroup.iterrows():\n",
    "                if row['dates'].month in {1,4,7,10} and row['dates'].day == 1:\n",
    "                    quarterly_dates.append(row['dates'])\n",
    "\n",
    "                    if row['dates'] > vintage: # or vintage < min_vintage_withvalue or row['dates'] < min_date_withvalue:\n",
    "                        quarterly_values.append(float('nan'))\n",
    "                    else:\n",
    "                        found = False\n",
    "                        i = index+1\n",
    "                        while found == False:\n",
    "                            if i == vgroup.shape[0] or (vgroup.loc[i, 'dates'].month == next_month[row['dates'].month] and vgroup.loc[i, 'dates'].day == 1):\n",
    "                                found = True\n",
    "                            else:\n",
    "                                i += 1\n",
    "                        quarterly_values.append(vgroup.loc[index:i, 'values'].mean())\n",
    "\n",
    "            vgroup = pd.DataFrame({'dates': quarterly_dates, 'values': quarterly_values})\n",
    "\n",
    "        vgroup.columns = ['dates', str(vintage.year) + 'Q' + str((vintage.month+2)//3)]\n",
    "        df2 = vgroup if vindex == 0 else pd.merge(df2, vgroup, how='outer')        \n",
    "    df2['fred_variables'] = varname\n",
    "    if not frequency == 'Q':\n",
    "        print()\n",
    "        \n",
    "    print(f'Merging ...')\n",
    "    # rename columns and merge all DataFrames\n",
    "    df_raw = df2 if varindex == 0 else pd.concat([df_raw, df2])\n",
    "    \n",
    "# re-arrange the order of the columns\n",
    "df_raw = df_raw[[df_raw.columns[0]] + [df_raw.columns[-1]] + list(df_raw.columns[1:-1])]\n",
    "df_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.fillna(float('nan'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "df_raw.to_csv('alfred_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('alfred_raw.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['dates'] = pd.to_datetime(df_raw['dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = ['UNR_US', 'LCPI_US', 'LGDP_US', 'RS_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47Q1 47Q2 47Q3 47Q4 48Q1 48Q2 48Q3 48Q4 49Q1 49Q2 49Q3 49Q4 50Q1 50Q2 50Q3 50Q4 51Q1 51Q2 51Q3 51Q4 52Q1 52Q2 52Q3 52Q4 53Q1 53Q2 53Q3 53Q4 54Q1 54Q2 54Q3 54Q4 55Q1 55Q2 55Q3 55Q4 56Q1 56Q2 56Q3 56Q4 57Q1 57Q2 57Q3 57Q4 58Q1 58Q2 58Q3 58Q4 59Q1 59Q2 59Q3 59Q4 60Q1 60Q2 60Q3 60Q4 61Q1 61Q2 61Q3 61Q4 62Q1 62Q2 62Q3 62Q4 63Q1 63Q2 63Q3 63Q4 64Q1 64Q2 64Q3 64Q4 65Q1 65Q2 65Q3 65Q4 66Q1 66Q2 66Q3 66Q4 67Q1 67Q2 67Q3 67Q4 68Q1 68Q2 68Q3 68Q4 69Q1 69Q2 69Q3 69Q4 70Q1 70Q2 70Q3 70Q4 71Q1 71Q2 71Q3 71Q4 72Q1 72Q2 72Q3 72Q4 73Q1 73Q2 73Q3 73Q4 74Q1 74Q2 74Q3 74Q4 75Q1 75Q2 75Q3 75Q4 76Q1 76Q2 76Q3 76Q4 77Q1 77Q2 77Q3 77Q4 78Q1 78Q2 78Q3 78Q4 79Q1 79Q2 79Q3 79Q4 80Q1 80Q2 80Q3 80Q4 81Q1 81Q2 81Q3 81Q4 82Q1 82Q2 82Q3 82Q4 83Q1 83Q2 83Q3 83Q4 84Q1 84Q2 84Q3 84Q4 85Q1 85Q2 85Q3 85Q4 86Q1 86Q2 86Q3 86Q4 87Q1 87Q2 87Q3 87Q4 88Q1 88Q2 88Q3 88Q4 89Q1 89Q2 89Q3 89Q4 90Q1 90Q2 90Q3 90Q4 91Q1 91Q2 91Q3 91Q4 92Q1 92Q2 92Q3 92Q4 93Q1 93Q2 93Q3 93Q4 94Q1 94Q2 94Q3 94Q4 95Q1 95Q2 95Q3 95Q4 96Q1 96Q2 96Q3 96Q4 97Q1 97Q2 97Q3 97Q4 98Q1 98Q2 98Q3 98Q4 99Q1 99Q2 99Q3 99Q4 00Q1 00Q2 00Q3 00Q4 01Q1 01Q2 01Q3 01Q4 02Q1 02Q2 02Q3 02Q4 03Q1 03Q2 03Q3 03Q4 04Q1 04Q2 04Q3 04Q4 05Q1 05Q2 05Q3 05Q4 06Q1 06Q2 06Q3 06Q4 07Q1 07Q2 07Q3 07Q4 08Q1 08Q2 08Q3 08Q4 09Q1 09Q2 09Q3 09Q4 10Q1 10Q2 10Q3 10Q4 11Q1 11Q2 11Q3 11Q4 12Q1 12Q2 12Q3 12Q4 13Q1 13Q2 13Q3 13Q4 14Q1 14Q2 14Q3 14Q4 15Q1 15Q2 15Q3 15Q4 16Q1 16Q2 16Q3 16Q4 17Q1 17Q2 17Q3 17Q4 18Q1 18Q2 18Q3 18Q4 19Q1 "
     ]
    }
   ],
   "source": [
    "df_observables = pd.DataFrame({'dates': list(df_raw['dates'].unique()) * len(observables), \n",
    "                               'observables': np.array([[observable] * len(df_raw['dates'].unique()) for observable in observables]).reshape(1, -1).tolist()[0]})\n",
    "\n",
    "for vintage in df_raw.columns[2:].tolist():\n",
    "    \n",
    "    print(vintage[2:], end=' ')\n",
    "    \n",
    "    # df_vintage\n",
    "    # column = ['dates', 'VARIABLE1', 'VARIABLE2', ...]\n",
    "    # row = ['date1', 'date2', ...]\n",
    "    temp = df_raw.loc[:, ['dates', 'fred_variables', vintage]].copy()\n",
    "    df_vintage = pd.DataFrame({'dates': df_raw['dates'].unique()})\n",
    "    for varname in fred_variables:\n",
    "        df_vintage[varname] = temp[temp['fred_variables']==varname][vintage].tolist()\n",
    "    \n",
    "    # observables\n",
    "    df_vintage['UNR_US'] = df_vintage['UNRATE']\n",
    "    df_vintage['LCPI_US'] = df_vintage['CPIAUCSL'].map(lambda x: np.log(x)*100)\n",
    "    df_vintage['LGDP_US'] = df_vintage['GDPC1'].map(lambda x: np.log(x)*100)\n",
    "    df_vintage['RS_US'] = df_vintage['FEDFUNDS']\n",
    "    \n",
    "    # concatenate the values of all observables\n",
    "    df_observables[vintage] = np.array(df_vintage[observables]).transpose().reshape(1, -1).tolist()[0]\n",
    "    \n",
    "df_observables.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_observables.iterrows():\n",
    "    for col in df_observables.columns[2:]:\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972Q3           NaN\n",
       "1972Q4           NaN\n",
       "1973Q1           NaN\n",
       "1973Q2           NaN\n",
       "1973Q3           NaN\n",
       "             ...    \n",
       "2018Q1    308.076252\n",
       "2018Q2    308.076252\n",
       "2018Q3    308.076252\n",
       "2018Q4    308.076252\n",
       "2019Q1    308.076252\n",
       "Name: 1947:Q1, Length: 187, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66538deb4d144fa6934c7f7321a635bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4d73ae3ab54a51b293d7e9e3898a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a263f6abd08a4175a5d834d4881f98ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466750797a2e40cea51390c0b7b8546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, group in df_observables.groupby('observables'):\n",
    "    group.loc[:, 'dates'] = group['dates'].map(lambda x: str(x.year)+':Q'+str(x.quarter)) # change date format\n",
    "    group.set_index('dates', drop=True, inplace=True) # set date as index\n",
    "    group.index.name = 'DATE' # change index name\n",
    "    group.drop('observables', axis=1, inplace=True) # drop the 'observables' column\n",
    "    \n",
    "    # drop some all NaN columns, otherwise \"column index (256) not an int in range(256)\"\n",
    "    drop_columns = [col for col in group.columns if all(np.isnan(group[col]))]\n",
    "    group.drop(drop_columns, axis=1, inplace=True) \n",
    "    \n",
    "    # fill nans\n",
    "    group_copy = group.copy()\n",
    "    for index, row in tqdm_notebook(group.iterrows(), total=group.shape[0]):\n",
    "        for col in group.columns:\n",
    "            if np.isnan(row[col]):\n",
    "                if int(col.replace('Q', '')) > int(index.replace(':Q', '')):\n",
    "                    group_copy.loc[index, col] = -99\n",
    "                else:\n",
    "                    group_copy.loc[index, col] = -999\n",
    "                    \n",
    "    group.columns = [name + col[-4:] for col in group.columns] # change column name\n",
    "    \n",
    "    group_copy.to_excel(os.getcwd()+'/withspf/'+name+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44307f9f4694ac4b2363626c717dbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfec64137954116bd95805f96172c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5204086297f4255a22f5ab0f45bb3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9abf57b9fc143f9858cf469daa3dee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=289), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, group in df_observables.groupby('observables'):\n",
    "    group.loc[:, 'dates'] = group['dates'].map(lambda x: str(x.year)+':Q'+str(x.quarter)) # change date format\n",
    "    group.set_index('dates', drop=True, inplace=True) # set date as index\n",
    "    group.index.name = 'DATE' # change index name\n",
    "    group.drop('observables', axis=1, inplace=True) # drop the 'observables' column\n",
    "    \n",
    "    # drop some all NaN columns, otherwise \"column index (256) not an int in range(256)\"\n",
    "    drop_columns = [col for col in group.columns if all(np.isnan(group[col]))]\n",
    "    group.drop(drop_columns, axis=1, inplace=True) \n",
    "    \n",
    "    # fill nans\n",
    "    group_copy = group.copy()\n",
    "    for index, row in tqdm_notebook(group.iterrows(), total=group.shape[0]):\n",
    "        for col in group.columns:\n",
    "            if np.isnan(row[col]):\n",
    "                if int(col.replace('Q', '')) > int(index.replace(':Q', '')):\n",
    "                    group_copy.loc[index, col] = -99\n",
    "                else:\n",
    "                    group_copy.loc[index, col] = -999\n",
    "            if int(col.replace('Q', '')) == int(index.replace(':Q', '')):\n",
    "                group_copy.loc[index, col] = -999\n",
    "                \n",
    "    group.columns = [name + col[-4:] for col in group.columns] # change column name\n",
    "    \n",
    "    group_copy.to_excel(os.getcwd()+'/withoutspf/'+name+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
